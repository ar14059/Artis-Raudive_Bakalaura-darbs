---
jupyter:
  jupytext:
    jupytext_formats: ipynb,Rmd:rmarkdown
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# Atslēdz auto-save iespēju
# %autosave 0
```

```{python}
# # # Importētie moduļi

# # "Grafiskie" moduļi
import rdfpandas.graph  # tika importeets Anaconda sisteemaa
import pandas as pd  # tika importeets Anaconda sisteemaa
from ipywidgets import widgets   # pievienots GUI (button, textbox u.tml.) + event handler
from IPython.display import clear_output # dod iespēju izdzēst sūnas "Out" saturu, izmantojot komandu

# # Pamata modulis darbam ar semantiskiem datiem
import rdflib # tika importēts Anaconda sistēmā

# # moduļi strukturētu (ne obligāti RDF) datu iegūšānai 
from urllib.request import urlopen, Request
import json

# # modulis SPARQL valodas pielietošanai saistīto datu iegūšanai 
from SPARQLWrapper import SPARQLWrapper, JSON 

# # Papildus moduļi datu apstrādei / analīzei
import datetime # var pārbaudīt, vai objekts ir datums
```

```{python}
# # # Sistēmas funkcijas un galvenie mainīgie (galvenokārt, vārdnīcas vai saraksti)

def rand_node(count):
    import random
    import string
    node = ""
    char_set = string.ascii_letters + "0123456789"
    for i in range(count):
        node += random.choice(char_set)
    return node


def val_type(v):
    return type(v).__name__
```

```{python}
# # # SPARQL izsaukumi

sparql_lang_wrapper = "https://databus.dbpedia.org/repo/sparql"
sparql_lang_query = """
    PREFIX dataid: <http://dataid.dbpedia.org/ns/core#>
    PREFIX dct:    <http://purl.org/dc/terms/>
    PREFIX dcat:   <http://www.w3.org/ns/dcat#>
    PREFIX db:     <https://databus.dbpedia.org/>
    PREFIX rdf:    <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
    PREFIX rdfs:   <http://www.w3.org/2000/01/rdf-schema#>

    SELECT DISTINCT ?l WHERE {
      ?s a dataid:Dataset ; dataid:artifact <https://databus.dbpedia.org/dbpedia/generic/labels> ; dcat:distribution ?d. 
      ?d <http://dataid.dbpedia.org/ns/cv#lang> ?l.
    } 
    LIMIT 1000
"""
def sparql_result(wrapper, query):    
    arr = []

    sparql = SPARQLWrapper(wrapper)
    sparql.setQuery(query)
    sparql.setReturnFormat(JSON)
    results = sparql.query().convert()
#     results
    for result in results["results"]["bindings"]:
        arr.append(result["l"]["value"])
    return arr

# def sparql_result(wrapper, query):    

sparql = SPARQLWrapper(sparql_lang_wrapper)
sparql.setQuery(sparql_lang_query)
sparql.setReturnFormat(JSON)
results = sparql.query().convert()
# results



# print(sparql_result(sparql_lang_wrapper, sparql_lang_query))
```

```{python}
# represents_type(s) - funkcija, kas pārbauda "Literal" vērtību, pārbauda, 
# kāds varētu būt tā datutips un izvada tā nosaukumu, balstoties uz 
# XMLSchema datutipiem (pagaidām tikai trīs tipi, 
# kas tika atrasti JSON struktūrā)



lang_arr = sparql_result(sparql_lang_wrapper, sparql_lang_query)
def represents_type(s):
    # OWL(varbūt) vārdnīcas
    
    uri_prefix_arr = ["http://","https://","uri:","_:"]
    try:
        datetime.datetime.strptime(s[0:10], "%Y-%m-%d")
        return "date"
    except:
        try:
            if(val_type(s) == "list"):
                return "list"
            else:
                raise ValueError() 
        except:   
            try:
                if(val_type(s) == "str"):
                    if(("." in s) and (float(s))):
                        return "decimal"
                    else:
                        raise ValueError()
                else:
                    if (isinstance(s, float)):
                        return "decimal"
                    else:
                        raise ValueError()      
            except:
                try:
                    int(s)
                    return "nonNegativeInteger"
                except:
                    try:
                        for pref in uri_prefix_arr:
                            if(s.startswith(pref)):
                                return "uri"
                        else:
                            raise ValueError()
                    except:
                        try:
                            if(s in lang_arr):
                                return "lang"
                            else:
                                raise ValueError()
                        except: 
                            try:
                                for lang in lang_arr:
                                    if(s.startswith(lang+"_")):
                                        return "lang_ext"
                                else:
                                    raise ValueError()
                            except: 
                                return "langString"




specific_ns = {"dbr" : rdflib.term.URIRef("http://dbpedia.org/resource/")}

# graph_to_prefix_table__DataFrame(rdf_graph) - funkcija, kas 
# saīsina URI, izmantojot PREFIX vērtības un pārveido datus, 
# lai tie tiktu smukāk attēloti "DataFrame" tabulā
def graph_to_prefix_table__DataFrame(rdf_graph):
    subject_array = []
    predicate_array = []
    object_array = []
    dict = {}

    # Pievieno prefiksus no:
    # DBPedia turtle formāta faila;
    for ns in rdf_graph.namespaces():
        dict[ns[0]] = ns[1]
    # speciālo prefiksu vārdnīcas
    for key,val in specific_ns.items():
        dict[key] = val

    # saīsina URI, izmantojot PREFIX vērtības
    for subj, pred, obj in rdf_graph:
#         for key,val in dict.items(): 
#             if (subj.startswith(val)):
#                 subj = subj.replace(val, key + ":")           
#             if (pred.startswith(val)):
#                 pred = pred.replace(val, key + ":")   
#             if (obj.startswith(val)):
#                 obj = subj.replace(val, key + ":")  

        subject_array.append( subj )
        predicate_array.append( pred )
        object_array.append( obj )

    # rindu (ierakstu) skaits tabulā      `
    pd.set_option('display.max_rows', len(subject_array)) 
    # kolonnas max iespējamais ievadāmo simb skaits
    pd.options.display.max_colwidth = max_width  
    
    return {'Subject': subject_array, 'Predicate': predicate_array, 'Object': object_array}
```

```{python}
# # # Kitsu API izveidotās funkcijas:

def schema_val(v, k=""):
    lang_type = ["lang", "lang_ext"]
    if(v==None or v==[] or v=={}):
#     if(v==None):
        v = "Null"
    
    if(represents_type(v) == "list"):
        v_modif = {}
        for v_el in v:
            schema_type = "https://www.w3.org/2001/XMLSchema#"
            schema_type += represents_type(v_el)
            v_modif.update({"@value": v_el, "@type": schema_type})
    else: 
        if(represents_type(k)=="lang"):
            v_modif = {"@value": v, "@language": k}
        elif(represents_type(k)=="lang_ext"):
            v_modif = {"@value": v, "language": k}     
        else:
            if(represents_type(v) != "str"):
                if(represents_type(v) == "uri"):
                    v_modif = {"@id": v}
                else:
                    schema_type = "https://www.w3.org/2001/XMLSchema#"
                    schema_type += represents_type(v)
                    v_modif = {"@value": v, "@type": schema_type}
            else: 
                schema_type = "http://www.w3.org/2001/XMLSchema#"
                schema_type += represents_type(v)
                v_modif = {"@value": v, "@type": schema_type}
    return v_modif


def dbp_uri(key, rel_type = ""):
    if(rel_type != ""):
        rel_type += "/"
    return "uri:kitsu/" + rel_type +  key
```

```{python}
k = "posterImage"
# v = {"w":{"e":{"r":{"t":{"y":"https://kitsu.io/api/edge/media-characters/17763"}}}}, "asdfg":12}
v = {
    "tiny": "https://media.kitsu.io/anime/poster_images/3/tiny.jpg?1529208785",
    "small": "https://media.kitsu.io/anime/poster_images/3/small.jpg?1529208785",
    "medium": "https://media.kitsu.io/anime/poster_images/3/medium.jpg?1529208785",
    "large": "https://media.kitsu.io/anime/poster_images/3/large.jpg?1529208785",
    "original": "https://media.kitsu.io/anime/poster_images/3/original.jpg?1529208785",
    "meta": {
        "dimensions": {
            "tiny": {
                "width": 110,
                "height": 156
            },
            "small": {
                "width": 284,
                "height": 402
            },
            "medium": {
                "width": 390,
                "height": 554
            },
            "large": {
                "width": 550,
                "height": 780
            }
        }
    }
}
def get_chained_dict_data(val, key_uri):
    tmp_dict = {}
    for chn_key, chn_val in val.items():
        chn_key_tmp = key_uri + "/" + chn_key
        if(val_type(chn_val) != "dict"):
            tmp_dict.update({dbp_uri(chn_key_tmp) : schema_val(chn_val)})
        else:
            if(chn_val == {}):
                tmp_dict.update({dbp_uri(chn_key_tmp) : schema_val(chn_val)})
            else:
                tmp_chain_dict = get_chained_dict_data(chn_val, chn_key_tmp)
                tmp_dict.update(tmp_chain_dict)
    return tmp_dict
# test_dict = get_chained_dict_data(v,k)
# print(json.dumps(test_dict))
```

```{python}
# next(iter(val)
tmp_list = {}
test_dict = {"createdAt": "2013-02-20T18:49:22.288Z","updatedAt": "2018-12-28T03:28:36.206Z","slug": "milly-thompson","names": {"en": "Milly Thompson","ja_jp": "ミリィ・トンプソン"}}

lang_type = ["lang", "lang_ext"]
for attr_key, attr_val in test_dict.items():
    if(val_type(attr_val)=="dict"):
        if(represents_type(next(iter(attr_val))) in lang_type):
            tmp_lang_arr = []
            for lang_key, lang_val in attr_val.items():
                tmp_lang_arr.append(schema_val(lang_val,lang_key))
            tmp_list.update({attr_key:tmp_lang_arr})
# print(json.dumps(tmp_list))
# print(val_type(test_dict))
```

```{python}

```

```{python}
headers = {"User-Agent": "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3"}
# headers = {"User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0"}

def get_kitsu_data_by_uri(uri, headers):
    try:
        req_url = uri
        req = Request(url=req_url, headers=headers) 
        json_api_content = urlopen(req).read().decode("UTF-8")
        # # ERROR 522 - nevar tikt pie API (problēma no kitsu puses)

        # kitsu_json_data - json fails parveidots vārdnīcas struktūrā 
        # un izņemts no ietvara "data"
        kitsu_json_data = json.loads(json_api_content)["data"]
        return kitsu_json_data
    except:
        return []



def get_certain_article_data(uri, main_data_types, including_rel, rel_second_level):
    tmp_data = get_kitsu_data_by_uri(uri, headers)
    tmp_list_arr = []
    uri
    if(val_type(tmp_data) == "dict"):
        data = [tmp_data]
    else:
        data = tmp_data
    
    if("type" in data[0]):
        tmp_rel_type = data[0]["type"]
    

    if(tmp_rel_type not in main_data_types):
        tmp_list_main = {}
        tmp_list_main.update({"@id":uri})
        consists_of = dbp_uri("consistsOf")
        tmp_list_main.update({consists_of:[]})
    
    for data_el in data:
        
        if(tmp_rel_type not in main_data_types):
            tmp_list_main[consists_of].append(schema_val(data_el["links"]["self"]))    
        
        tmp_list = {}  
        dont_need = ["createdAt", "updatedAt"]

        for key, val in data_el.items():
            if(key == "links"):
                tmp_list.update({"@id":val["self"]})
            elif(key == "type"):
                tmp_list.update({"@type":val}) 
            elif(key == "attributes"): 
                for attr_key, attr_val in val.items():
                    if(val_type(attr_val)=="dict"):
                        if(represents_type(next(iter(attr_val))) in lang_type):
                            final_key = dbp_uri(attr_key)
                            tmp_lang_arr = []
                            for lang_key, lang_val in attr_val.items():
                                tmp_lang_arr.append(schema_val(lang_val,lang_key))   
                            tmp_list.update({final_key:tmp_lang_arr})
                        else: 
                            tmp_chained_data = get_chained_dict_data(attr_val, attr_key)
                            tmp_list.update(tmp_chained_data)
                    else:
                        if(attr_key not in dont_need):
                            final_key = dbp_uri(attr_key, tmp_rel_type)
                            tmp_list.update({final_key:[schema_val(attr_val)]})   

            elif(key == "relationships"): 
                if(tmp_rel_type not in main_data_types):
                    for rel_key, rel_val in val.items():
                        if(tmp_rel_type in rel_second_level and rel_key in rel_second_level[tmp_rel_type]):
                            snd_level_rel_uri = rel_val["links"]["related"]

                            final_key = dbp_uri(rel_key)
                            tmp_list.update({final_key:[schema_val(snd_level_rel_uri)]})

                            tmp_list_arr_2nd_level = get_certain_article_data(snd_level_rel_uri, main_data_types, including_rel, rel_second_level)

                            for el_1st in tmp_list_arr_2nd_level:
                                tmp_list_arr.append(el_1st)
                else:

                    for rel_key, rel_val in val.items():
                        if(rel_key in including_rel):
                            snd_level_rel_uri = rel_val["links"]["related"]

                            final_key = dbp_uri(rel_key)

                            tmp_list.update({final_key:[schema_val(snd_level_rel_uri)]})
                            
                            tmp_list_arr_2nd_level = get_certain_article_data(snd_level_rel_uri, main_data_types, including_rel, rel_second_level)
                            for el_1st in tmp_list_arr_2nd_level:
                                tmp_list_arr.append(el_1st)
        tmp_list_arr.append(tmp_list)
        
    if(tmp_rel_type not in main_data_types):  
        tmp_list_arr.append(tmp_list_main)
    
    return tmp_list_arr

# qw = get_certain_article_data("https://kitsu.io/api/edge/anime/3")
# qw = get_certain_article_data("https://kitsu.io/api/edge/anime/3/genres")
# qw = get_certain_article_data("https://kitsu.io/api/edge/anime/3/categories")
# qw = get_certain_article_data("https://kitsu.io/api/edge/anime/3/anime-characters")
# qw = get_certain_article_data("https://kitsu.io/api/edge/anime/3/castings")

# print(json.dumps(qw))





def get_article_data(uri):
    main_data_types = ["anime", "manga", "drama"]
    if("anime" in uri):
        including_rel = ["genres", "categories", "castings", "reviews",
                         "episodes", "animeProductions",
                        "animeCharacters", "animeStaff"]
        rel_second_level = {"castings":"people/person", "reviews": "users", "animeCharacters": "character",
                        "animeStaff": "people", "animeProductions":"producer"}
    
    
    
#     elif("manga" in uri):
#         including_rel = ["genres", "categories", "castings", "reviews",
#                          "chapters", "mangaCharacters", "mangaStaff"]
#         second_level = {"castings":"people/person", "reviews": "users", "mangaCharacters": "character",
#                         "mangaStaff": "people", "animeProductions":"producer"}  

        
        
#     elif("drama" in uri):
#         including_rel = ["genres", "categories", "castings", "reviews",
#                          "episodes", "animeProductions",
#                         "animeCharacters", "animeStaff"]
#         second_level = {"castings":"people/person", "reviews": "users", "animeCharacters": "character",
#                         "animeStaff": "people", "animeProductions":"producer"}  
        
    certaian_article_data = get_certain_article_data(uri, main_data_types, including_rel, rel_second_level)
    return certaian_article_data

ex_uri = "https://kitsu.io/api/edge/anime/3"
kitsu_data_ex = get_article_data(ex_uri)
print(json.dumps(kitsu_data_ex))
```

```{python}

```

```{python}

```

```{python}


```

```{python}

```

```{python}

# # # Datu grafi no RDFlib moduļa, kas reprezentē pētāmos RDF datus

# # Kitsu API:
kitsu_jsonld_file_path = '''
C:\\Users\\TTB_Detagari\\Google Drive\\LU\\4. kurss\\8. semestris
\\BAKALAURA DARBS\\Python\\Jupyter\\jsonld_data.jsonld.json"
'''


```

```{python}

```

```{python}
# # # Datu grafi no RDFlib moduļa, kas reprezentē pētāmos RDF datus



# # DBPedia:
ttl_file_path = '''
C:\\Users\\TTB_Detagari\\Google Drive\\LU\\4. kurss\\8. semestris\\BAKALAURA DARBS\\
Python\\Jupyter\\rdf_content.ttl'
'''
ttl_vocabulary_path = '''
C:\\Users\\TTB_Detagari\\Google Drive\\LU\\4. kurss\\8. 
semestris\\BAKALAURA DARBS\\Python\\Jupyter\\vocabulary.ttl
'''
g_kitsu = rdflib.Graph()
# g_kitsu_data = g_kitsu.parse(data=bytes(json.dumps(rec_tmp_data),encoding='utf8'), format='json-ld')
g_kitsu_data = g_kitsu.parse(data=bytes(json.dumps(kitsu_data_ex),encoding='utf8'), format='json-ld')
# g_kitsu_data_2 = g_kitsu.parse(data=bytes(json.dumps(k_data_all[1]),encoding='utf8'), format='json-ld')

# # DBPedia API:

g_DBp = rdflib.Graph()
g_DBp.load("http://dbpedia.org/resource/Death_Note")

# for s, p, o in g_DBp:
#     print(s)
#     print(p)
#     print(o)
#     print("")

# for s, p, o in g_kitsu_data:
#     print(s)
#     print(p)
#     print(o)
#     print("")

# g_DBp.load("http://dbpedia.org/resource/KonoSuba")
```

```{python}
# # # Pārveido izvada vizuālo izskatu 


# Palielina ekrāna izmēru kodam un izvadam līdz ekrāna izmēŗam - 100%
from IPython.core.display import display, HTML
display(HTML("<style>.container { width:100% !important; }</style>"))

# balstoties uz subj/pred/obj simbolu garumiem, tiks noteikts 
# maksimālais simbolu skaits visām tabulas kolonnas šūnām
max_width = 10
for subj, pred, obj in g_DBp: 
    if(len(subj) > max_width):
        max_width = len(subj)
    elif(len(pred) > max_width):
        max_width = len(pred)
    elif(len(obj) > max_width):
        max_width = len(obj) 
```

```{python}
### informācijas savākšans no DBPedia linka

d1 = graph_to_prefix_table__DataFrame(g_DBp)
df1 = pd.DataFrame(data=d1)
df1 = df1.style.set_properties(**{'text-align': 'left'})

d2 = graph_to_prefix_table__DataFrame(g_kitsu_data)
df2 = pd.DataFrame(data=d2)
df2 = df2.style.set_properties(**{'text-align': 'left'})
# d1
# d2
```

```{python}
####### SVARĪGS IZVADS, NEDZĒST #########
# print(json.dumps(rec_tmp_data))
```

```{python}
g_DBp_ex = rdflib.Graph()
g_DBp_ex.load("http://dbpedia.org/resource/Template:Infobox_animanga/Header")
d3 = graph_to_prefix_table__DataFrame(g_DBp_ex)
df3 = pd.DataFrame(data=d3)
df3 = df3.style.set_properties(**{'text-align': 'left'})
# d3
```

```{python}
# # # Vizuālais interfeiss


dbp_button = widgets.Button(description="DBPedia")
display(dbp_button)
kitsu_button = widgets.Button(description="Kitsu API")
display(kitsu_button)

out = widgets.Output()
def on_button_clicked(b):
    with out:
        clear_output(True)
        if(b.description == "DBPedia"):
            clear_output(True)
            display(df1)
        else:
            clear_output(True)
            display(df2)
#             display(df3)

dbp_button.on_click(on_button_clicked)
kitsu_button.on_click(on_button_clicked)

out
```

```{python}
### Usefull code

## Datu ierakstīšana failā
# s = g.serialize(format='ttl')
# f = open(ttl_file_path, 'wb')
# f.write(s)
# f.close()
# json.dumps(rec_tmp_data)

```

```{python}
# import wptools

# page = wptools.page('Death_Note')
# page.get_parse()
# page.data['infobox'][0]
# # page.data['infobox']
```
